{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdOY9gZ5EuQT",
    "colab_type": "text"
   },
   "source": [
    "## PRZEGLĄD RÓŻNYCH KLASYFIKACJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "zGQ0XXw0QHJK",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# K-NN - K NAJBLIŻSZYCH SĄSIADÓW\n",
    "# KERNEL K-NN - DODAJE WAGI ZWIĄZANE Z ODLEGŁOŚIA DO SĄSIADÓW\n",
    "# MLP - MULTILAYER PERCEPTRON\n",
    "names = [\"k-NN\", \"kernel k-NN\", \"MLP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "K7XVZ5DeQMCZ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "classifiers = [KNeighborsClassifier(),\n",
    "               KNeighborsClassifier(weights='distance'),\n",
    "               MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                             hidden_layer_sizes=(5, 2), random_state=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "vyMtK3ouQiNv",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# KOD POTRZEBNY DO ŁADNEJ WIZUALIZACJI WYNIKÓW RAZEM Z PRZYKŁADOWYMI DANYMI\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def draw_graph(names, classifiers):\n",
    "\n",
    "    h = .02\n",
    "\n",
    "    X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                               random_state=None, n_clusters_per_class=1)\n",
    "    rng = np.random.seed(2)\n",
    "    X += 2 * np.random.uniform(size=X.shape)\n",
    "    linearly_separable = (X, y)\n",
    "\n",
    "    datasets = [make_moons(noise=0.3, random_state=None),\n",
    "                make_circles(noise=0.2, factor=0.5, random_state=None),\n",
    "                linearly_separable\n",
    "                ]\n",
    "\n",
    "    figure = plt.figure(figsize=(27, 9))\n",
    "    i = 1\n",
    "    # iterate over datasets\n",
    "    for ds_cnt, ds in enumerate(datasets):\n",
    "        # preprocess dataset, split into training and test part\n",
    "        X, y = ds\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "        x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "        y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                             np.arange(y_min, y_max, h))\n",
    "\n",
    "        # just plot the dataset first\n",
    "        cm = plt.cm.RdBu\n",
    "        cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(\"Input data\")\n",
    "        # Plot the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "                   edgecolors='k')\n",
    "        # Plot the testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "                   edgecolors='k')\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        i += 1\n",
    "\n",
    "        # iterate over classifiers\n",
    "        for name, clf in zip(names, classifiers):\n",
    "            ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "\n",
    "            # Plot the decision boundary. For that, we will assign a color to each\n",
    "            # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "            if hasattr(clf, \"decision_function\"):\n",
    "                Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "            else:\n",
    "                Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "            # Put the result into a color plot\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "            # Plot the training points\n",
    "            ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "                       edgecolors='k')\n",
    "            # Plot the testing points\n",
    "            ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                       edgecolors='k', alpha=0.6)\n",
    "\n",
    "            ax.set_xlim(xx.min(), xx.max())\n",
    "            ax.set_ylim(yy.min(), yy.max())\n",
    "            ax.set_xticks(())\n",
    "            ax.set_yticks(())\n",
    "            if ds_cnt == 0:\n",
    "                ax.set_title(name)\n",
    "            ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                    size=15, horizontalalignment='right')\n",
    "            i += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "p7LsOwfkQNXy",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "draw_graph(names, classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbdv32KKE9xp",
    "colab_type": "text"
   },
   "source": [
    "## PODSTAWOWE TRENOWANIE MODELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "s4oYhOzl7EZC",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "OOLEp4DG7EZR",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# ZBIÓR DANYCH O IRYSACH (4 WYMIARY) SPOŚRÓD DOMYŚLNYCH TRENINGOWYCH ZBIORÓW SCIKIT-LEARN (tzw. \"TOY DATASETS\"),\n",
    "#   OPIS TUTAJ: http://archive.ics.uci.edu/ml/datasets/Iris?ref=datanews.io\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "bU8uqzHT7EZc",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# \"TOY DATASETS\" MAJĄ POLA, W KTÓRYCH SĄ JUŻ WYDZIELONE PARAMETRY ORAZ DANE DOCELOWE  \n",
    "iris_parameters = iris.data # PARAMETRY - DŁUGOŚCI I SZEROKOŚCI PŁATKÓW ORAZ ŁODYGI IRYSÓW\n",
    "iris_values = iris.target # WARTOŚCI - TYPY IRYSÓW (3 RÓŻNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "vZfi1XAt7EZh",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# PRZYGOTOWANIE DO LOSOWEJ INICJALIZACJI ZBIORU TRENINGOWEGO I TESTOWEGO\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(iris_parameters))\n",
    "test_percent = 15.0\n",
    "test_set_size = int(len(iris_parameters) * test_percent / 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "b3hnR4Ik7EZn",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# INICJALIZACJA ZBIORU TRENINGOWEGO I TESTOWEGO\n",
    "iris_parameters_train = iris_parameters[indices[:-test_set_size]]\n",
    "iris_values_train = iris_values[indices[:-test_set_size]]\n",
    "iris_parameters_test = iris_parameters[indices[-test_set_size:]]\n",
    "iris_values_test = iris_values[indices[-test_set_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "_NfqWO-N7EZt",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# PRZYGOTOWANIE KLASYFIKATORA NAJBLIŻSZYCH SĄSIADÓW\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Ya_3ikKo7EZw",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# TRENOWANIE MODELU NA ZBIORACH TRENINGOWYCH\n",
    "knn.fit(iris_parameters_train, iris_values_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "DwfNeG-O7EZ3",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# UŻYCIE MODELU NA ZBIORZE TESTOWYM\n",
    "predicted_values = knn.predict(iris_parameters_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "myPCf-dJ7EZ8",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# PIERWSZYCH KILKA WARTOŚCI PRZEWIDZIANYCH PRZEZ MODEL NA ZBIORZE TESTOWYM\n",
    "predicted_values[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "WxYwj1PQ7EaA",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# PIERWSZYCH KILKA WARTOŚCI RZECZYWISTYCH W ZBIORZE TESTOWYM\n",
    "iris_values_test[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ryKTA1vN7EaF",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# SPRAWDZENIE JAKOŚCI KLASYFIKACJI (PROCENT POPRAWNYCH ODPOWIEDZI)\n",
    "correct = len([i for i, j in zip(predicted_values, iris_values_test) if i == j])\n",
    "correct_percent = correct / len(predicted_values)\n",
    "print(correct_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ol3ImwY5FPmA",
    "colab_type": "text"
   },
   "source": [
    "## TRENOWANIE MODELU NA DANYCH WCZYTANYCH Z PLIKU\n",
    "## ZNOWU UŻYJEMY DANYCH O IRYSACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2-db10Lu7EaU",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898.0
    },
    "outputId": "78241528-ae78-4048-c8a0-af5ef9dbb9c6"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-03a628064d34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miris_from_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iris_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_from_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0miris_from_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'iris_data' does not exist"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# WCZYTUJEMY DANE Z PLIKU ZA POMOCĄ PANDAS\n",
    "iris_from_file = pandas.read_csv('iris_data')\n",
    "print(type(iris_from_file))\n",
    "iris_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "UMzT6INm7EaY",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# SPROWADZAMY RAMKĘ Z DANYMI BIBLIOTEKI PANDAS TO TABLICY NUMPY\n",
    "iris_matrix = iris_from_file.as_matrix()\n",
    "print(type(iris_matrix))\n",
    "iris_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Z45UcRwK7Eaf",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Z PLIKU WYODRĘBNIAMY TO, CO JEST ATRYBUTAMI I KOLUMNĘ, KTÓRA JEST WARTOŚCIĄ JAKO LISTY\n",
    "iris_file_data = [flower[:4] for flower in iris_matrix]\n",
    "iris_file_values = [flower[4] for flower in iris_matrix]\n",
    "print(type(iris_file_data))\n",
    "print(type(iris_file_values))\n",
    "print(iris_file_data[:10])\n",
    "print(iris_file_values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ANPYMp9p7Eaj",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# ROBIMY Z TYCH LIST TABLICE NUMPY\n",
    "iris_parameters = np.array(iris_file_data)\n",
    "not_mapped_iris_values = np.array(iris_file_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "bgTgLBY77Ean",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# PRZEKSZTAŁCAMY TABLICĘ CIĄGÓW ZNAKÓW NA TABLICĘ ODPOWIADAJĄCYCH IM WARTOŚCI LICZBOWYCH\n",
    "unique_flowers = np.unique(not_mapped_iris_values)\n",
    "indices_map = {}\n",
    "for i in range(0,len(unique_flowers)):\n",
    "    indices_map[unique_flowers[i]] = i\n",
    "\n",
    "iris_values = np.array([indices_map[name] for name in not_mapped_iris_values])\n",
    "print(iris_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "S1GnByHk7Ear",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# TERAZ MAMY GOTOWE TAKIE SAME DANE JAK WCZEŚNIEJ, MOŻEMY POWTÓRZYĆ KLASYFIKACJĘ\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(iris_parameters))\n",
    "test_percent = 20.0\n",
    "test_set_size = int(len(iris_parameters) * test_percent / 100.0)\n",
    "iris_parameters_train = iris_parameters[indices[:-test_set_size]]\n",
    "iris_values_train = iris_values[indices[:-test_set_size]]\n",
    "iris_parameters_test = iris_parameters[indices[-test_set_size:]]\n",
    "iris_values_test = iris_values[indices[-test_set_size:]]\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(iris_parameters_train, iris_values_train)\n",
    "predicted_values = knn.predict(iris_parameters_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "io-lomWE7Eav",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# SPRAWDZENIE JAKOŚCI KLASYFIKACJI\n",
    "correct = len([i for i, j in zip(predicted_values, iris_values_test) if i == j])\n",
    "correct_percent = correct / len(predicted_values)\n",
    "print(correct_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44sd-FL7Fd2u",
    "colab_type": "text"
   },
   "source": [
    "## WCZYTANIE DANYCH TEKSTOWYCH I WYTRENOWANIE MODELU NA NICH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "zvpQYGA97Ea2",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "0QQ0cAQw7Ea4",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# ograniczymy się tylko do tych czterech kategorii dla uproszczenia\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "zu9mQwHb7Ea7",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# używamy domyślnych danych z sklearn.datasets\n",
    "dataset = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "_SKyBGu57EbC",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "print(dataset.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "CbWSlwfJ7EbI",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "print(dataset.target[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "SgB_nJ707EbL",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# przygotowujemy zbiory danych\n",
    "set_data = np.array(dataset.data)\n",
    "set_target = np.array(dataset.target)\n",
    "indices = np.random.permutation(len(set_data))\n",
    "test_percent = 15.0\n",
    "test_set_size = int(len(set_data) * test_percent / 100.0)\n",
    "parameters_train = set_data[indices[:-test_set_size]]\n",
    "values_train = set_target[indices[:-test_set_size]]\n",
    "parameters_test = set_data[indices[-test_set_size:]]\n",
    "values_test = set_target[indices[-test_set_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "1b4dPlU37EbS",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JYxjavw07EbV",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "arguments = count_vect.fit_transform(parameters_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "mFYvR9cr7EbX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# przygotowujemy argumenty do TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_arguments = tfidf_transformer.fit_transform(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "lIixXGXs7Eba",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# dopasowanie za pomocą naiwnego klasyfikatora bayes'owskiego\n",
    "clf = MultinomialNB().fit(tfidf_arguments, values_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "r3e6nN4D7Ebd",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "X_new_counts = count_vect.transform(parameters_test)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "h6iFTFaO7Ebf",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_new_tfidf)\n",
    "actual = values_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "hwRrDpjF7Ebh",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "print(predicted[:30])\n",
    "print(actual[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "RqUHv2VS7Ebl",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "correct = len([i for i, j in zip(predicted, actual) if i == j])\n",
    "correct_percent = correct / len(predicted)\n",
    "print(correct_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZVTDUiJFig_",
    "colab_type": "text"
   },
   "source": [
    "## BEZ NORMALIZACJI - ZBIÓR 147-WYMIAROWY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "IkZK4XoF7Eb1",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "pandas_data_from_file = pandas.read_csv('testing.csv')\n",
    "matrix_data = pandas_data_from_file.as_matrix()\n",
    "single_node_length = len(matrix_data[0])\n",
    "arg_number = 0\n",
    "list_arguments = [node[1:single_node_length] for node in matrix_data[:10000]]\n",
    "list_values = [node[0] for node in matrix_data[:10000]]\n",
    "\n",
    "values2 = np.array(list_values)\n",
    "\n",
    "unique_values = np.unique(values2)\n",
    "indices_map = {}\n",
    "for j in range(0, len(unique_values)):\n",
    "    indices_map[unique_values[j]] = j\n",
    "\n",
    "arguments = np.array(list_arguments)\n",
    "# values = np.array(values2)\n",
    "values = np.array([indices_map[name] for name in values2])\n",
    "\n",
    "data_len = len(arguments)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "indices = np.random.permutation(data_len)\n",
    "\n",
    "test_percent = 15.0\n",
    "\n",
    "test_set_size = int(data_len * test_percent / 100.0)\n",
    "\n",
    "parameters_train = arguments[indices[:-test_set_size]]\n",
    "values_train = values[indices[:-test_set_size]]\n",
    "parameters_test = arguments[indices[-test_set_size:]]\n",
    "values_test = values[indices[-test_set_size:]]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(parameters_train, values_train)\n",
    "\n",
    "predicted_values = knn.predict(parameters_test)\n",
    "print(\"\\nNUMBER OF DIMENSIONS: {}\".format(single_node_length - 1))\n",
    "correct = len([i for i, j in zip(predicted_values, values_test) if i == j])\n",
    "correct_percent = correct / len(predicted_values)\n",
    "print(correct_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfxZjq93Fs-f",
    "colab_type": "text"
   },
   "source": [
    "## BEZ NORMALIZACJI - ZBIÓR 34-WYMIAROWY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "I4mx5qGl7Ebt",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "pandas_data_from_file = pandas.read_csv('dimcurs.data')\n",
    "matrix_data = pandas_data_from_file.as_matrix()\n",
    "single_node_length = len(matrix_data[0])\n",
    "arg_number = 4\n",
    "\n",
    "list_arguments = [np.array(node[:arg_number].tolist() + node[arg_number:single_node_length].tolist()) for node in matrix_data[:10000]]\n",
    "list_values = [node[arg_number] for node in matrix_data[:10000]]\n",
    "\n",
    "arguments = np.array(list_arguments)\n",
    "values = np.array(list_values)\n",
    "\n",
    "data_len = len(arguments)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "indices = np.random.permutation(data_len)\n",
    "\n",
    "test_percent = 15.0\n",
    "\n",
    "test_set_size = int(data_len * test_percent / 100.0)\n",
    "\n",
    "parameters_train = arguments[indices[:-test_set_size]]\n",
    "values_train = values[indices[:-test_set_size]]\n",
    "parameters_test = arguments[indices[-test_set_size:]]\n",
    "values_test = values[indices[-test_set_size:]]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\")\n",
    "knn.fit(parameters_train, values_train)\n",
    "\n",
    "predicted_values = knn.predict(parameters_test)\n",
    "print(\"\\nNUMBER OF DIMENSIONS: {}\".format(single_node_length - 1))\n",
    "correct = len([i for i, j in zip(predicted_values, values_test) if i == j])\n",
    "correct_percent = correct / len(predicted_values)\n",
    "print(correct_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "nrX3e45VvGjl",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    result = []\n",
    "    maxmins = []\n",
    "\n",
    "    for i in range(0, len(array[0])):\n",
    "        maxmins.append({\n",
    "            'max': max(\n",
    "                [k for k in\n",
    "                 [row[i] for row in array]\n",
    "                 ]\n",
    "            ),\n",
    "            'min': min(\n",
    "                [k for k in\n",
    "                 [row[i] for row in array]\n",
    "                 ]\n",
    "            )\n",
    "        }\n",
    "        )\n",
    "\n",
    "    print(maxmins)\n",
    "    for row in array:\n",
    "        new_row = []\n",
    "        for j in range(len(row)):\n",
    "            maximum = maxmins[j]['max']\n",
    "            minimum = maxmins[j]['min']\n",
    "            size = maximum - minimum\n",
    "            value = row[j]\n",
    "            normalized_value = (value - minimum) / size\n",
    "            new_row.append(normalized_value)\n",
    "        result.append(new_row)\n",
    "\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKHdyVFsFxny",
    "colab_type": "text"
   },
   "source": [
    "## NORMALIZACJA - ZBIÓR 147-WYMIAROWY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "O7OLqEKOw_qx",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "pandas_data_from_file = pandas.read_csv('testing.csv')\n",
    "matrix_data = pandas_data_from_file.as_matrix()\n",
    "single_node_length = len(matrix_data[0])\n",
    "arg_number = 0\n",
    "list_arguments = [node[1:single_node_length] for node in matrix_data[:10000]]\n",
    "list_values = [node[0] for node in matrix_data[:10000]]\n",
    "\n",
    "values2 = np.array(list_values)\n",
    "\n",
    "unique_values = np.unique(values2)\n",
    "indices_map = {}\n",
    "for j in range(0, len(unique_values)):\n",
    "    indices_map[unique_values[j]] = j\n",
    "\n",
    "arguments = np.array(list_arguments)\n",
    "values = np.array([indices_map[name] for name in values2])\n",
    "\n",
    "# NORMALIZATION\n",
    "arguments = normalize(arguments)\n",
    "\n",
    "\n",
    "data_len = len(arguments)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "indices = np.random.permutation(data_len)\n",
    "\n",
    "test_percent = 15.0\n",
    "\n",
    "test_set_size = int(data_len * test_percent / 100.0)\n",
    "\n",
    "parameters_train = arguments[indices[:-test_set_size]]\n",
    "values_train = values[indices[:-test_set_size]]\n",
    "parameters_test = arguments[indices[-test_set_size:]]\n",
    "values_test = values[indices[-test_set_size:]]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(parameters_train, values_train)\n",
    "\n",
    "predicted_values = knn.predict(parameters_test)\n",
    "print(\"\\nNUMBER OF DIMENSIONS: {}\".format(single_node_length - 1))\n",
    "correct = len([i for i, j in zip(predicted_values, values_test) if i == j])\n",
    "correct_percent = correct / len(predicted_values)\n",
    "print(correct_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGj3SHKdF3pl",
    "colab_type": "text"
   },
   "source": [
    "## NORMALIZACJA - ZBIÓR 34-WYMIAROWY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "apuHoCz6wK2l",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "pandas_data_from_file = pandas.read_csv('dimcurs.data')\n",
    "matrix_data = pandas_data_from_file.as_matrix()\n",
    "single_node_length = len(matrix_data[0])\n",
    "arg_number = 4\n",
    "\n",
    "list_arguments = [np.array(node[:arg_number].tolist() + node[arg_number:single_node_length].tolist()) for node in matrix_data[:10000]]\n",
    "list_values = [node[arg_number] for node in matrix_data[:10000]]\n",
    "\n",
    "arguments = np.array(list_arguments)\n",
    "values = np.array(list_values)\n",
    "\n",
    "# NORMALIZATION\n",
    "arguments = normalize(arguments)\n",
    "\n",
    "data_len = len(arguments)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "indices = np.random.permutation(data_len)\n",
    "\n",
    "test_percent = 15.0\n",
    "\n",
    "test_set_size = int(data_len * test_percent / 100.0)\n",
    "\n",
    "parameters_train = arguments[indices[:-test_set_size]]\n",
    "values_train = values[indices[:-test_set_size]]\n",
    "parameters_test = arguments[indices[-test_set_size:]]\n",
    "values_test = values[indices[-test_set_size:]]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\")\n",
    "knn.fit(parameters_train, values_train)\n",
    "\n",
    "predicted_values = knn.predict(parameters_test)\n",
    "print(\"\\nNUMBER OF DIMENSIONS: {}\".format(single_node_length - 1))\n",
    "correct = len([i for i, j in zip(predicted_values, values_test) if i == j])\n",
    "correct_percent = correct / len(predicted_values)\n",
    "print(correct_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfyd7s1WEirE",
    "colab_type": "text"
   },
   "source": [
    "##  PRZEGLĄD RÓŹNYCH METRYK LICZENIA ODLEGŁOŚCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "nO4s4bsT7EcZ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "SK3BpJMK7Eca",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# METRYKA EUKLIDESOWA: sqrt(sum((x - y)^2))\n",
    "# METRYKA MINKOWSKIEGO: sum(|x - y|^p)^(1/p)\n",
    "# METRYKA MANHATTAN: sum(|x - y|)\n",
    "# METRYKA CZEBYSZEWA: max(|x - y|)\n",
    "names = [\"k-NN euclidean\", \"k-NN minkowski\", \"k-NN manhattan\", \"k-NN chebyshev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "FurtO28S7Ecd",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# KLASYFIKACJA ZA POMOCĄ RÓŹNYCH METRYK\n",
    "classifiers = [KNeighborsClassifier(metric='euclidean'),\n",
    "               KNeighborsClassifier(metric='minkowski', p=3),\n",
    "               KNeighborsClassifier(metric='manhattan'),\n",
    "               KNeighborsClassifier(metric='chebyshev')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "8TiqLNc97Eci",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "draw_graph(names, classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujYBRP8oEYLY",
    "colab_type": "text"
   },
   "source": [
    "## RYSOWANIE HISTOGRAMU ODLEGŁOŚCI DLA IRYSÓW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "B6xsKiosASyc",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "iris_from_file = pandas.read_csv('iris_data')\n",
    "\n",
    "iris_matrix = iris_from_file.as_matrix()\n",
    "iris_file_data = [[flower[0], flower[1], flower[2], flower[3]] for flower in iris_matrix]\n",
    "distances = []\n",
    "\n",
    "for iris_parameter in iris_file_data:\n",
    "    distances += euclidean_distances(iris_file_data, [iris_parameter]).tolist()\n",
    "\n",
    "distances = [x[0] for x in distances if x[0] != 0.]\n",
    "\n",
    "num_bins = 20\n",
    "sns.set_style(\"whitegrid\")\n",
    "n, bins, patches = plt.hist(distances, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.title('Histogram')\n",
    "plt.ylabel('Number of elements')\n",
    "plt.xlabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNG60Sw4ED7E",
    "colab_type": "text"
   },
   "source": [
    "##RYSOWANIE HISTOGRAMU ODLEGŁOŚCI DLA ZBIORU 147 WYMIAROWEGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJiBH_2PClB7",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "data_from_file = pandas.read_csv('testing.csv')\n",
    "\n",
    "data_matrix = data_from_file.as_matrix()\n",
    "data_file_data = [\n",
    "    [feature for feature in elem if feature != elem[0]] \n",
    "    for elem in data_matrix\n",
    "]\n",
    "distances = []\n",
    "\n",
    "for data_parameter in data_file_data:\n",
    "    distances += euclidean_distances(data_file_data, [data_parameter]).tolist()\n",
    "\n",
    "distances = [x[0] for x in distances if x[0] != 0.]\n",
    "\n",
    "num_bins = 40\n",
    "sns.set_style(\"whitegrid\")\n",
    "n, bins, patches = plt.hist(distances, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.title('Histogram')\n",
    "plt.ylabel('Number of elements')\n",
    "plt.xlabel('Distance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sklearn_tutorial (1).ipynb",
   "version": "0.3.2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
